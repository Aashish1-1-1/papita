{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3J9-cQJAHMWV",
        "outputId": "f01df7ab-431d-4dbd-e878-9500300bb44a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar 23 16:03:57 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "3590aosvz4YS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "oJ8dAHhNv-YY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define"
      ],
      "metadata": {
        "id": "TGmQ6SbA0An5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "num_epochs = 20\n",
        "\n",
        "# Device will determine whether to run the training on GPU or CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "FvWAqB4AwCrj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load Dataset/to-do to fix to custom dataset"
      ],
      "metadata": {
        "id": "JBG8JPCJ0IBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use transforms.compose method to reformat images for modeling,\n",
        "# and save to variable all_transforms for later use\n",
        "all_transforms = transforms.Compose([transforms.Resize((32,32)),\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],\n",
        "                                                          std=[0.2023, 0.1994, 0.2010])\n",
        "                                     ])\n",
        "# Create Training dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                             train = True,\n",
        "                                             transform = all_transforms,\n",
        "                                             download = True)\n",
        "\n",
        "# Create Testing dataset\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = './data',\n",
        "                                            train = False,\n",
        "                                            transform = all_transforms,\n",
        "                                            download=True)\n",
        "\n",
        "# Instantiate loader objects to facilitate processing\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd0CpM9RwIe4",
        "outputId": "f2e3539b-263a-4cd8-fa32-940937087083"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN class inheriting from nn"
      ],
      "metadata": {
        "id": "EWOJsejq0SRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a CNN class\n",
        "class ConvNeuralNet(nn.Module):\n",
        "#  Determine what layers and their order in CNN object\n",
        "    def __init__(self, num_classes):\n",
        "        super(ConvNeuralNet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.conv_layer2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.conv_layer3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.conv_layer4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3)\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(1600, 128)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    # Progresses data across layers\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.max_pool1(out)\n",
        "\n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.max_pool2(out)\n",
        "\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.relu1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "i9G9pL2Uwcx5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instantiate CNN class"
      ],
      "metadata": {
        "id": "Cd9o8q4x0b6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNeuralNet(num_classes)\n",
        "\n",
        "# Set Loss function with criterion\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Set optimizer with optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay = 0.005, momentum = 0.9)\n",
        "\n",
        "total_step = len(train_loader)"
      ],
      "metadata": {
        "id": "V21ZCA_Mwkbn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training"
      ],
      "metadata": {
        "id": "fo9J4Lpd0oU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "# Load in the data in batches using the train_loader object\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Move the model to the configured device\n",
        "        model = model.to(device) # This line is added to move the model to the GPU\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjgXzaG_wnyh",
        "outputId": "d3d8b300-65e0-43f9-dbd3-457b25b2903f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 1.8930\n",
            "Epoch [2/20], Loss: 1.4949\n",
            "Epoch [3/20], Loss: 1.5860\n",
            "Epoch [4/20], Loss: 1.4868\n",
            "Epoch [5/20], Loss: 1.3496\n",
            "Epoch [6/20], Loss: 1.1079\n",
            "Epoch [7/20], Loss: 1.0235\n",
            "Epoch [8/20], Loss: 1.0097\n",
            "Epoch [9/20], Loss: 1.7313\n",
            "Epoch [10/20], Loss: 0.4997\n",
            "Epoch [11/20], Loss: 0.9091\n",
            "Epoch [12/20], Loss: 1.2004\n",
            "Epoch [13/20], Loss: 0.5632\n",
            "Epoch [14/20], Loss: 0.8383\n",
            "Epoch [15/20], Loss: 0.5343\n",
            "Epoch [16/20], Loss: 0.8353\n",
            "Epoch [17/20], Loss: 0.8141\n",
            "Epoch [18/20], Loss: 0.6089\n",
            "Epoch [19/20], Loss: 0.7425\n",
            "Epoch [20/20], Loss: 0.5483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing"
      ],
      "metadata": {
        "id": "ejS8Qpkz0s0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the {} train images: {} %'.format(50000, 100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnscNdVQxPE5",
        "outputId": "08df2aff-a04e-4207-d68e-5ed6c2100613"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 50000 train images: 82.792 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using ONNX runtime for production"
      ],
      "metadata": {
        "id": "pdQ_ih3R02EX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwKj_7BszLCw",
        "outputId": "c27e1f90-cc3b-46cb-9e53-2c7becca4410"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.3)\n",
            "Downloading onnx-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exporting file for production use"
      ],
      "metadata": {
        "id": "3tkIWnWe09v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dummy_input = torch.randn(1, 3, 32, 32)  # Example: 1 image, 3 channels, 32x32 size\n",
        "\n",
        "# Move the dummy input to the same device as the model\n",
        "dummy_input = dummy_input.to(device) # Move dummy_input to device\n",
        "\n",
        "# Export the model to ONNX formatm\n",
        "torch.onnx.export(model, dummy_input, \"cifar10_model.onnx\", verbose=True)\n",
        "\n",
        "print(\"Model saved as cifar10_model.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld5sQfFxyT9X",
        "outputId": "51b32be8-1485-48e0-85db-16fdc813beae"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as cifar10_model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Only for google drive"
      ],
      "metadata": {
        "id": "2HNJ0ekg1DOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: download that file to my system\n",
        "\n",
        "from google.colab import files\n",
        "files.download('cifar10_model.onnx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-VuKFToSzTWQ",
        "outputId": "f94bb334-6aa5-4dc9-9128-13e7b082042f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_10f9df61-a0a0-4e26-bb8d-5070e780423a\", \"cifar10_model.onnx\", 1124810)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}